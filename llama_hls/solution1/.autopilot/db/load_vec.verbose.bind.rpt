

================================================================
== Vitis HLS Report for 'load_vec'
================================================================
* Date:           Mon Sep 15 01:27:48 2025

* Version:        2025.1 (Build 6135595 on May 21 2025)
* Project:        llama_hls
* Solution:       solution1 (Vivado IP Flow Target)
* Product family: versalhbm
* Target device:  xcv80-lsva4737-2MHP-e-S


================================================================
== Performance Estimates
================================================================
+ Timing: 
    * Summary: 
    +--------+---------+----------+------------+
    |  Clock |  Target | Estimated| Uncertainty|
    +--------+---------+----------+------------+
    |ap_clk  |  4.00 ns|  2.191 ns|     1.08 ns|
    +--------+---------+----------+------------+

+ Latency: 
    * Summary: 
    +---------+---------+----------+----------+-----+-----+------------------------------------------------+
    |  Latency (cycles) |  Latency (absolute) |  Interval |                    Pipeline                    |
    |   min   |   max   |    min   |    max   | min | max |                      Type                      |
    +---------+---------+----------+----------+-----+-----+------------------------------------------------+
    |      770|      770|  3.080 us|  3.080 us|  769|  769|  loop auto-rewind stp (delay=0 clock cycles(s))|
    +---------+---------+----------+----------+-----+-----+------------------------------------------------+

    + Detail: 
        * Instance: 
        N/A

        * Loop: 
        +----------+---------+---------+----------+-----------+-----------+------+----------+
        |          |  Latency (cycles) | Iteration|  Initiation Interval  | Trip |          |
        | Loop Name|   min   |   max   |  Latency |  achieved |   target  | Count| Pipelined|
        +----------+---------+---------+----------+-----------+-----------+------+----------+
        |- mem_rd  |      768|      768|         2|          1|          1|   768|       yes|
        +----------+---------+---------+----------+-----------+-----------+------+----------+

============================================================
+ Verbose Summary: Synthesis Manager
============================================================
InlineROM: 1
ExposeGlobal: 0
============================================================
+ Verbose Summary: CDFG Model
============================================================
IsTopModel: 0
ResetActiveHigh: 1
IsCombinational: 2
IsDatapathOnly: 0
HasWiredReturn: 1
HasMFsm: 2
HasVarLatency: 1
IsPipeline: 0
IsRtlPipelined: 0
IsInstanceOverlapped: 0
IsDontTouch: 0
HasImplIP: 0
IsGatedGlobalClock: 0

+ Individual pipeline summary: 
  * Pipeline-0: initiation interval (II) = 1, depth = 2


============================================================
+ Verbose Summary: Schedule
============================================================
* Number of FSM states : 2
* Pipeline : 1
  Pipeline-0 : II = 1, D = 2, States = { 1 2 }
* Dataflow Pipeline: 0

* FSM state transitions: 
1 --> 2 
2 --> 

* FSM state operations: 

State 1 <SV = 0> <Delay = 2.15>
ST_1 : Operation 5 [1/1] (0.00ns)   --->   "%i = alloca i32 1" [kernel_rmsnorm.cpp:11]   --->   Operation 5 'alloca' 'i' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 6 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i32 %input1_stream, void @empty_39, i32 0, i32 0, void @empty_48, i32 0, i32 0, void @empty_48, void @empty_48, void @empty_48, i32 0, i32 0, i32 0, i32 0, void @empty_48, void @empty_48, i32 4294967295, i32 0, i32 0"   --->   Operation 6 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 7 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i32 %input1_stream, void @empty_39, i32 0, i32 0, void @empty_48, i32 0, i32 0, void @empty_48, void @empty_48, void @empty_48, i32 0, i32 0, i32 0, i32 0, void @empty_48, void @empty_48, i32 4294967295, i32 0, i32 0"   --->   Operation 7 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 8 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i32 %input1_stream, void @empty_39, i32 0, i32 0, void @empty_48, i32 0, i32 0, void @empty_48, void @empty_48, void @empty_48, i32 0, i32 0, i32 0, i32 0, void @empty_48, void @empty_48, i32 4294967295, i32 0, i32 0"   --->   Operation 8 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 9 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i32 %input1_stream, void @empty_39, i32 0, i32 0, void @empty_48, i32 0, i32 0, void @empty_48, void @empty_48, void @empty_48, i32 0, i32 0, i32 0, i32 0, void @empty_48, void @empty_48, i32 4294967295, i32 0, i32 0"   --->   Operation 9 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 10 [1/1] (0.39ns)   --->   "%store_ln11 = store i10 0, i10 %i" [kernel_rmsnorm.cpp:11]   --->   Operation 10 'store' 'store_ln11' <Predicate = true> <Delay = 0.39>
ST_1 : Operation 11 [1/1] (0.00ns)   --->   "%br_ln11 = br void %for.inc.i" [kernel_rmsnorm.cpp:11]   --->   Operation 11 'br' 'br_ln11' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 12 [1/1] (0.00ns)   --->   "%i_15 = load i10 %i" [kernel_rmsnorm.cpp:11]   --->   Operation 12 'load' 'i_15' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 13 [1/1] (0.71ns)   --->   "%add_ln11 = add i10 %i_15, i10 1" [kernel_rmsnorm.cpp:11]   --->   Operation 13 'add' 'add_ln11' <Predicate = true> <Delay = 0.71> <CoreInst = "Adder">   --->   Core 1 'Adder' <Latency = 0> <II = 1> <Delay = 0.71> <FuncUnit> <Opcode : 'add' 'sub'> <InPorts = 2> <OutPorts = 1>
ST_1 : Operation 14 [1/1] (0.60ns)   --->   "%icmp_ln11 = icmp_eq  i10 %i_15, i10 768" [kernel_rmsnorm.cpp:11]   --->   Operation 14 'icmp' 'icmp_ln11' <Predicate = true> <Delay = 0.60> <CoreInst = "ICmp_EQ">   --->   Core 156 'ICmp_EQ' <Latency = 0> <II = 1> <Delay = 0.60> <FuncUnit> <Opcode : 'seteq' 'setne'> <InPorts = 2> <OutPorts = 1>
ST_1 : Operation 15 [1/1] (0.00ns)   --->   "%br_ln11 = br i1 %icmp_ln11, void %for.inc.split.i, void %load_vec.exit" [kernel_rmsnorm.cpp:11]   --->   Operation 15 'br' 'br_ln11' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 16 [1/1] (0.00ns)   --->   "%trunc_ln11 = trunc i10 %i_15" [kernel_rmsnorm.cpp:11]   --->   Operation 16 'trunc' 'trunc_ln11' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 17 [1/1] (0.00ns)   --->   "%lshr_ln = partselect i8 @_ssdm_op_PartSelect.i8.i10.i32.i32, i10 %i_15, i32 2, i32 9" [kernel_rmsnorm.cpp:11]   --->   Operation 17 'partselect' 'lshr_ln' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 18 [1/1] (0.00ns)   --->   "%zext_ln11 = zext i8 %lshr_ln" [kernel_rmsnorm.cpp:11]   --->   Operation 18 'zext' 'zext_ln11' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 19 [1/1] (0.00ns)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_24 = getelementptr i32 %llama_inference_hls_top_float_float_float_float_float_float_float_7, i64 0, i64 %zext_ln11" [kernel_rmsnorm.cpp:14]   --->   Operation 19 'getelementptr' 'llama_inference_hls_top_float_float_float_float_float_float_float_24' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 20 [1/1] (0.00ns)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_25 = getelementptr i32 %llama_inference_hls_top_float_float_float_float_float_float_float_6, i64 0, i64 %zext_ln11" [kernel_rmsnorm.cpp:14]   --->   Operation 20 'getelementptr' 'llama_inference_hls_top_float_float_float_float_float_float_float_25' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 21 [1/1] (0.00ns)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_26 = getelementptr i32 %llama_inference_hls_top_float_float_float_float_float_float_float_5, i64 0, i64 %zext_ln11" [kernel_rmsnorm.cpp:14]   --->   Operation 21 'getelementptr' 'llama_inference_hls_top_float_float_float_float_float_float_float_26' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 22 [1/1] (0.00ns)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_27 = getelementptr i32 %llama_inference_hls_top_float_float_float_float_float_float_float_4, i64 0, i64 %zext_ln11" [kernel_rmsnorm.cpp:14]   --->   Operation 22 'getelementptr' 'llama_inference_hls_top_float_float_float_float_float_float_float_27' <Predicate = (!icmp_ln11)> <Delay = 0.00>
ST_1 : Operation 23 [1/1] (0.43ns) (share mux size 4)   --->   "%muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28 = muxlogic i8 %llama_inference_hls_top_float_float_float_float_float_float_float_24"   --->   Operation 23 'muxlogic' 'muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28' <Predicate = (!icmp_ln11)> <Delay = 0.43>
ST_1 : Operation 24 [2/2] (0.71ns) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_28 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_24" [kernel_rmsnorm.cpp:14]   --->   Operation 24 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_28' <Predicate = (!icmp_ln11)> <Delay = 0.71> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_1 : Operation 25 [1/1] (0.43ns) (share mux size 4)   --->   "%muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29 = muxlogic i8 %llama_inference_hls_top_float_float_float_float_float_float_float_25"   --->   Operation 25 'muxlogic' 'muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29' <Predicate = (!icmp_ln11)> <Delay = 0.43>
ST_1 : Operation 26 [2/2] (0.71ns) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_29 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_25" [kernel_rmsnorm.cpp:14]   --->   Operation 26 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_29' <Predicate = (!icmp_ln11)> <Delay = 0.71> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_1 : Operation 27 [1/1] (0.43ns) (share mux size 4)   --->   "%muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30 = muxlogic i8 %llama_inference_hls_top_float_float_float_float_float_float_float_26"   --->   Operation 27 'muxlogic' 'muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30' <Predicate = (!icmp_ln11)> <Delay = 0.43>
ST_1 : Operation 28 [2/2] (0.71ns) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_30 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_26" [kernel_rmsnorm.cpp:14]   --->   Operation 28 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_30' <Predicate = (!icmp_ln11)> <Delay = 0.71> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_1 : Operation 29 [1/1] (0.43ns) (share mux size 4)   --->   "%muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31 = muxlogic i8 %llama_inference_hls_top_float_float_float_float_float_float_float_27"   --->   Operation 29 'muxlogic' 'muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31' <Predicate = (!icmp_ln11)> <Delay = 0.43>
ST_1 : Operation 30 [2/2] (0.71ns) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_31 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_27" [kernel_rmsnorm.cpp:14]   --->   Operation 30 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_31' <Predicate = (!icmp_ln11)> <Delay = 0.71> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_1 : Operation 31 [1/1] (0.39ns)   --->   "%store_ln11 = store i10 %add_ln11, i10 %i" [kernel_rmsnorm.cpp:11]   --->   Operation 31 'store' 'store_ln11' <Predicate = (!icmp_ln11)> <Delay = 0.39>
ST_1 : Operation 44 [1/1] (0.28ns)   --->   "%ret_ln0 = ret"   --->   Operation 44 'ret' 'ret_ln0' <Predicate = (icmp_ln11)> <Delay = 0.28>

State 2 <SV = 1> <Delay = 2.19>
ST_2 : Operation 32 [1/1] (0.00ns)   --->   "%specpipeline_ln12 = specpipeline void @_ssdm_op_SpecPipeline, i32 1, i32 0, i32 0, i32 0, void @empty_48" [kernel_rmsnorm.cpp:12]   --->   Operation 32 'specpipeline' 'specpipeline_ln12' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 33 [1/1] (0.00ns)   --->   "%speclooptripcount_ln13 = speclooptripcount void @_ssdm_op_SpecLoopTripCount, i64 768, i64 768, i64 768" [kernel_rmsnorm.cpp:13]   --->   Operation 33 'speclooptripcount' 'speclooptripcount_ln13' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 34 [1/1] (0.00ns)   --->   "%specloopname_ln11 = specloopname void @_ssdm_op_SpecLoopName, void @empty_36" [kernel_rmsnorm.cpp:11]   --->   Operation 34 'specloopname' 'specloopname_ln11' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 35 [1/2] ( I:0.89ns O:0.89ns ) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_28 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_24" [kernel_rmsnorm.cpp:14]   --->   Operation 35 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_28' <Predicate = true> <Delay = 0.89> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_2 : Operation 36 [1/2] ( I:0.89ns O:0.89ns ) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_29 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_25" [kernel_rmsnorm.cpp:14]   --->   Operation 36 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_29' <Predicate = true> <Delay = 0.89> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_2 : Operation 37 [1/2] ( I:0.89ns O:0.89ns ) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_30 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_26" [kernel_rmsnorm.cpp:14]   --->   Operation 37 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_30' <Predicate = true> <Delay = 0.89> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_2 : Operation 38 [1/2] ( I:0.89ns O:0.89ns ) (share mux size 8)   --->   "%llama_inference_hls_top_float_float_float_float_float_float_float_31 = load i8 %llama_inference_hls_top_float_float_float_float_float_float_float_27" [kernel_rmsnorm.cpp:14]   --->   Operation 38 'load' 'llama_inference_hls_top_float_float_float_float_float_float_float_31' <Predicate = true> <Delay = 0.89> <CoreInst = "RAM">   --->   Core 86 'RAM' <Latency = 1> <II = 1> <Delay = 0.89> <Storage> <Opcode : 'load' 'store'> <Ports = 2> <Width = 32> <Depth = 192> <RAM>
ST_2 : Operation 39 [1/1] (0.43ns)   --->   "%tmp_i = sparsemux i32 @_ssdm_op_SparseMux.ap_auto.4float.float.i2, i2 0, i32 %llama_inference_hls_top_float_float_float_float_float_float_float_28, i2 1, i32 %llama_inference_hls_top_float_float_float_float_float_float_float_29, i2 2, i32 %llama_inference_hls_top_float_float_float_float_float_float_float_30, i2 3, i32 %llama_inference_hls_top_float_float_float_float_float_float_float_31, i32 <undef>, i2 %trunc_ln11" [kernel_rmsnorm.cpp:14]   --->   Operation 39 'sparsemux' 'tmp_i' <Predicate = true> <Delay = 0.43> <CoreInst = "BinarySparseMux_DontCare">   --->   Core 150 'BinarySparseMux_DontCare' <Latency = 0> <II = 1> <Delay = 0.43> <FuncUnit> <Opcode : 'sparsemux'> <InPorts = 0> <OutPorts = 1>
ST_2 : Operation 40 [1/1] (0.00ns)   --->   "%bitcast_ln14 = bitcast i32 %tmp_i" [kernel_rmsnorm.cpp:14]   --->   Operation 40 'bitcast' 'bitcast_ln14' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 41 [1/1] (0.00ns)   --->   "%muxLogicFIFOData_to_write_ln14 = muxlogic i32 %bitcast_ln14"   --->   Operation 41 'muxlogic' 'muxLogicFIFOData_to_write_ln14' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 42 [1/1] ( I:0.86ns O:0.86ns )   --->   "%write_ln14 = write void @_ssdm_op_Write.ap_fifo.volatile.i32P0A, i32 %input1_stream, i32 %bitcast_ln14" [kernel_rmsnorm.cpp:14]   --->   Operation 42 'write' 'write_ln14' <Predicate = true> <Delay = 0.86> <CoreInst = "FIFO_SRL">   --->   Core 84 'FIFO_SRL' <Latency = 0> <II = 1> <Delay = 0.86> <Storage> <Opcode : 'read' 'write' 'nbread' 'nbwrite'> <Ports = 0> <Width = 32> <Depth = 32> <FIFO>
ST_2 : Operation 43 [1/1] (0.00ns)   --->   "%br_ln11 = br void %for.inc.i" [kernel_rmsnorm.cpp:11]   --->   Operation 43 'br' 'br_ln11' <Predicate = true> <Delay = 0.00>


============================================================
+ Verbose Summary: Binding
============================================================
STG Binding: 
---------------- STG Properties BEGIN ----------------
- Is combinational: 0
- Is one-state seq: 0
- Is datapath-only: 0
- Is pipelined: 0
- Is top level: 0
Port [ Return ] is wired: 1; IO mode=ap_ctrl_hs:ce=0
Port [ llama_inference_hls_top_float_float_float_float_float_float_float_7]:  wired=1; compound=1; hidden=0; nouse=0; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[13]; IO mode=ap_memory:ce=0
Port [ llama_inference_hls_top_float_float_float_float_float_float_float_6]:  wired=1; compound=1; hidden=0; nouse=0; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[13]; IO mode=ap_memory:ce=0
Port [ llama_inference_hls_top_float_float_float_float_float_float_float_5]:  wired=1; compound=1; hidden=0; nouse=0; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[13]; IO mode=ap_memory:ce=0
Port [ llama_inference_hls_top_float_float_float_float_float_float_float_4]:  wired=1; compound=1; hidden=0; nouse=0; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[13]; IO mode=ap_memory:ce=0
Port [ input1_stream]:  wired=1; compound=1; hidden=0; nouse=0; global=1; static=1; extern=0; dir=1; type=3; pingpong=0; private_global=0; IO mode=ap_fifo:ce=0
---------------- STG Properties END ------------------

---------------- Datapath Model BEGIN ----------------

<LifeTime>
<method=bitvector/>
i                                                                                       (alloca           ) [ 010]
specinterface_ln0                                                                       (specinterface    ) [ 000]
specinterface_ln0                                                                       (specinterface    ) [ 000]
specinterface_ln0                                                                       (specinterface    ) [ 000]
specinterface_ln0                                                                       (specinterface    ) [ 000]
store_ln11                                                                              (store            ) [ 000]
br_ln11                                                                                 (br               ) [ 000]
i_15                                                                                    (load             ) [ 000]
add_ln11                                                                                (add              ) [ 000]
icmp_ln11                                                                               (icmp             ) [ 010]
br_ln11                                                                                 (br               ) [ 000]
trunc_ln11                                                                              (trunc            ) [ 011]
lshr_ln                                                                                 (partselect       ) [ 000]
zext_ln11                                                                               (zext             ) [ 000]
llama_inference_hls_top_float_float_float_float_float_float_float_24                    (getelementptr    ) [ 011]
llama_inference_hls_top_float_float_float_float_float_float_float_25                    (getelementptr    ) [ 011]
llama_inference_hls_top_float_float_float_float_float_float_float_26                    (getelementptr    ) [ 011]
llama_inference_hls_top_float_float_float_float_float_float_float_27                    (getelementptr    ) [ 011]
muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28 (muxlogic         ) [ 000]
muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29 (muxlogic         ) [ 000]
muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30 (muxlogic         ) [ 000]
muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31 (muxlogic         ) [ 000]
store_ln11                                                                              (store            ) [ 000]
specpipeline_ln12                                                                       (specpipeline     ) [ 000]
speclooptripcount_ln13                                                                  (speclooptripcount) [ 000]
specloopname_ln11                                                                       (specloopname     ) [ 000]
llama_inference_hls_top_float_float_float_float_float_float_float_28                    (load             ) [ 000]
llama_inference_hls_top_float_float_float_float_float_float_float_29                    (load             ) [ 000]
llama_inference_hls_top_float_float_float_float_float_float_float_30                    (load             ) [ 000]
llama_inference_hls_top_float_float_float_float_float_float_float_31                    (load             ) [ 000]
tmp_i                                                                                   (sparsemux        ) [ 000]
bitcast_ln14                                                                            (bitcast          ) [ 000]
muxLogicFIFOData_to_write_ln14                                                          (muxlogic         ) [ 000]
write_ln14                                                                              (write            ) [ 000]
br_ln11                                                                                 (br               ) [ 000]
ret_ln0                                                                                 (ret              ) [ 000]
</LifeTime>

<model>

<comp_list>
<comp id="0" class="1000" name="llama_inference_hls_top_float_float_float_float_float_float_float_7">
<pin_list>
<pin id="1" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="llama_inference_hls_top_float_float_float_float_float_float_float_7"/><MemPortTyVec>1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="2" class="1000" name="llama_inference_hls_top_float_float_float_float_float_float_float_6">
<pin_list>
<pin id="3" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="llama_inference_hls_top_float_float_float_float_float_float_float_6"/><MemPortTyVec>1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="4" class="1000" name="llama_inference_hls_top_float_float_float_float_float_float_float_5">
<pin_list>
<pin id="5" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="llama_inference_hls_top_float_float_float_float_float_float_float_5"/><MemPortTyVec>1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="6" class="1000" name="llama_inference_hls_top_float_float_float_float_float_float_float_4">
<pin_list>
<pin id="7" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="llama_inference_hls_top_float_float_float_float_float_float_float_4"/><MemPortTyVec>1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="8" class="1000" name="input1_stream">
<pin_list>
<pin id="9" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="input1_stream"/></StgValue>
</bind>
</comp>

<comp id="10" class="1001" name="const_10">
<pin_list>
<pin id="11" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="12" class="1001" name="const_12">
<pin_list>
<pin id="13" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecInterface"/></StgValue>
</bind>
</comp>

<comp id="14" class="1001" name="const_14">
<pin_list>
<pin id="15" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_39"/></StgValue>
</bind>
</comp>

<comp id="16" class="1001" name="const_16">
<pin_list>
<pin id="17" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="18" class="1001" name="const_18">
<pin_list>
<pin id="19" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_48"/></StgValue>
</bind>
</comp>

<comp id="20" class="1001" name="const_20">
<pin_list>
<pin id="21" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="22" class="1001" name="const_22">
<pin_list>
<pin id="23" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="24" class="1001" name="const_24">
<pin_list>
<pin id="25" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="26" class="1001" name="const_26">
<pin_list>
<pin id="27" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="28" class="1001" name="const_28">
<pin_list>
<pin id="29" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_PartSelect.i8.i10.i32.i32"/></StgValue>
</bind>
</comp>

<comp id="30" class="1001" name="const_30">
<pin_list>
<pin id="31" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="32" class="1001" name="const_32">
<pin_list>
<pin id="33" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="34" class="1001" name="const_34">
<pin_list>
<pin id="35" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="36" class="1001" name="const_36">
<pin_list>
<pin id="37" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecPipeline"/></StgValue>
</bind>
</comp>

<comp id="38" class="1001" name="const_38">
<pin_list>
<pin id="39" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecLoopTripCount"/></StgValue>
</bind>
</comp>

<comp id="40" class="1001" name="const_40">
<pin_list>
<pin id="41" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="42" class="1001" name="const_42">
<pin_list>
<pin id="43" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecLoopName"/></StgValue>
</bind>
</comp>

<comp id="44" class="1001" name="const_44">
<pin_list>
<pin id="45" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_36"/></StgValue>
</bind>
</comp>

<comp id="46" class="1001" name="const_46">
<pin_list>
<pin id="47" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SparseMux.ap_auto.4float.float.i2"/></StgValue>
</bind>
</comp>

<comp id="48" class="1001" name="const_48">
<pin_list>
<pin id="49" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="50" class="1001" name="const_50">
<pin_list>
<pin id="51" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="52" class="1001" name="const_52">
<pin_list>
<pin id="53" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="54" class="1001" name="const_54">
<pin_list>
<pin id="55" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="56" class="1001" name="const_56">
<pin_list>
<pin id="57" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="58" class="1001" name="const_58">
<pin_list>
<pin id="59" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_Write.ap_fifo.volatile.i32P0A"/></StgValue>
</bind>
</comp>

<comp id="60" class="1004" name="i_fu_60">
<pin_list>
<pin id="61" dir="0" index="0" bw="1" slack="0"/>
<pin id="62" dir="1" index="1" bw="10" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="i/1 "/>
</bind>
</comp>

<comp id="64" class="1004" name="write_ln14_write_fu_64">
<pin_list>
<pin id="65" dir="0" index="0" bw="0" slack="0"/>
<pin id="66" dir="0" index="1" bw="32" slack="0"/>
<pin id="67" dir="0" index="2" bw="32" slack="0"/>
<pin id="68" dir="1" index="3" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="write(1151) " fcode="write"/>
<opset="write_ln14/2 "/>
</bind>
</comp>

<comp id="71" class="1004" name="llama_inference_hls_top_float_float_float_float_float_float_float_24_gep_fu_71">
<pin_list>
<pin id="72" dir="0" index="0" bw="32" slack="0"/>
<pin id="73" dir="0" index="1" bw="1" slack="0"/>
<pin id="74" dir="0" index="2" bw="8" slack="0"/>
<pin id="75" dir="1" index="3" bw="8" slack="0"/>
</pin_list>
<bind>
<opcode="getelementptr(29) " fcode="getelementptr"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_24/1 "/>
</bind>
</comp>

<comp id="78" class="1004" name="llama_inference_hls_top_float_float_float_float_float_float_float_25_gep_fu_78">
<pin_list>
<pin id="79" dir="0" index="0" bw="32" slack="0"/>
<pin id="80" dir="0" index="1" bw="1" slack="0"/>
<pin id="81" dir="0" index="2" bw="8" slack="0"/>
<pin id="82" dir="1" index="3" bw="8" slack="0"/>
</pin_list>
<bind>
<opcode="getelementptr(29) " fcode="getelementptr"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_25/1 "/>
</bind>
</comp>

<comp id="85" class="1004" name="llama_inference_hls_top_float_float_float_float_float_float_float_26_gep_fu_85">
<pin_list>
<pin id="86" dir="0" index="0" bw="32" slack="0"/>
<pin id="87" dir="0" index="1" bw="1" slack="0"/>
<pin id="88" dir="0" index="2" bw="8" slack="0"/>
<pin id="89" dir="1" index="3" bw="8" slack="0"/>
</pin_list>
<bind>
<opcode="getelementptr(29) " fcode="getelementptr"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_26/1 "/>
</bind>
</comp>

<comp id="92" class="1004" name="llama_inference_hls_top_float_float_float_float_float_float_float_27_gep_fu_92">
<pin_list>
<pin id="93" dir="0" index="0" bw="32" slack="0"/>
<pin id="94" dir="0" index="1" bw="1" slack="0"/>
<pin id="95" dir="0" index="2" bw="8" slack="0"/>
<pin id="96" dir="1" index="3" bw="8" slack="0"/>
</pin_list>
<bind>
<opcode="getelementptr(29) " fcode="getelementptr"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_27/1 "/>
</bind>
</comp>

<comp id="99" class="1004" name="grp_access_fu_99">
<pin_list>
<pin id="100" dir="0" index="0" bw="8" slack="0"/>
<pin id="101" dir="0" index="1" bw="32" slack="2147483647"/>
<pin id="102" dir="0" index="2" bw="0" slack="2147483647"/>
<pin id="103" dir="1" index="3" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_28/1 "/>
</bind>
</comp>

<comp id="105" class="1004" name="grp_access_fu_105">
<pin_list>
<pin id="106" dir="0" index="0" bw="8" slack="0"/>
<pin id="107" dir="0" index="1" bw="32" slack="2147483647"/>
<pin id="108" dir="0" index="2" bw="0" slack="2147483647"/>
<pin id="109" dir="1" index="3" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_29/1 "/>
</bind>
</comp>

<comp id="111" class="1004" name="grp_access_fu_111">
<pin_list>
<pin id="112" dir="0" index="0" bw="8" slack="0"/>
<pin id="113" dir="0" index="1" bw="32" slack="2147483647"/>
<pin id="114" dir="0" index="2" bw="0" slack="2147483647"/>
<pin id="115" dir="1" index="3" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_30/1 "/>
</bind>
</comp>

<comp id="117" class="1004" name="grp_access_fu_117">
<pin_list>
<pin id="118" dir="0" index="0" bw="8" slack="0"/>
<pin id="119" dir="0" index="1" bw="32" slack="2147483647"/>
<pin id="120" dir="0" index="2" bw="0" slack="2147483647"/>
<pin id="121" dir="1" index="3" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_31/1 "/>
</bind>
</comp>

<comp id="123" class="1004" name="store_ln11_store_fu_123">
<pin_list>
<pin id="124" dir="0" index="0" bw="1" slack="0"/>
<pin id="125" dir="0" index="1" bw="10" slack="0"/>
<pin id="126" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln11/1 "/>
</bind>
</comp>

<comp id="128" class="1004" name="i_15_load_fu_128">
<pin_list>
<pin id="129" dir="0" index="0" bw="10" slack="0"/>
<pin id="130" dir="1" index="1" bw="10" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="i_15/1 "/>
</bind>
</comp>

<comp id="131" class="1004" name="add_ln11_fu_131">
<pin_list>
<pin id="132" dir="0" index="0" bw="10" slack="0"/>
<pin id="133" dir="0" index="1" bw="1" slack="0"/>
<pin id="134" dir="1" index="2" bw="10" slack="0"/>
</pin_list>
<bind>
<opcode="add(8) " fcode="add"/>
<opset="add_ln11/1 "/>
</bind>
</comp>

<comp id="137" class="1004" name="icmp_ln11_fu_137">
<pin_list>
<pin id="138" dir="0" index="0" bw="10" slack="0"/>
<pin id="139" dir="0" index="1" bw="9" slack="0"/>
<pin id="140" dir="1" index="2" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<opcode="icmp(45) " fcode="icmp"/>
<opset="icmp_ln11/1 "/>
</bind>
</comp>

<comp id="143" class="1004" name="trunc_ln11_fu_143">
<pin_list>
<pin id="144" dir="0" index="0" bw="10" slack="0"/>
<pin id="145" dir="1" index="1" bw="2" slack="1"/>
</pin_list>
<bind>
<opcode="trunc(33) " fcode="trunc"/>
<opset="trunc_ln11/1 "/>
</bind>
</comp>

<comp id="147" class="1004" name="lshr_ln_fu_147">
<pin_list>
<pin id="148" dir="0" index="0" bw="8" slack="0"/>
<pin id="149" dir="0" index="1" bw="10" slack="0"/>
<pin id="150" dir="0" index="2" bw="3" slack="0"/>
<pin id="151" dir="0" index="3" bw="5" slack="0"/>
<pin id="152" dir="1" index="4" bw="8" slack="0"/>
</pin_list>
<bind>
<opcode="partselect(1002) " fcode="partselect"/>
<opset="lshr_ln/1 "/>
</bind>
</comp>

<comp id="157" class="1004" name="zext_ln11_fu_157">
<pin_list>
<pin id="158" dir="0" index="0" bw="8" slack="0"/>
<pin id="159" dir="1" index="1" bw="64" slack="0"/>
</pin_list>
<bind>
<opcode="zext(34) " fcode="zext"/>
<opset="zext_ln11/1 "/>
</bind>
</comp>

<comp id="165" class="1004" name="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28_fu_165">
<pin_list>
<pin id="166" dir="0" index="0" bw="8" slack="0"/>
<pin id="167" dir="1" index="1" bw="32" slack="2147483647"/>
</pin_list>
<bind>
<opcode="muxlogic(592) " fcode="muxlogic"/>
<opset="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28/1 "/>
</bind>
</comp>

<comp id="169" class="1004" name="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29_fu_169">
<pin_list>
<pin id="170" dir="0" index="0" bw="8" slack="0"/>
<pin id="171" dir="1" index="1" bw="32" slack="2147483647"/>
</pin_list>
<bind>
<opcode="muxlogic(592) " fcode="muxlogic"/>
<opset="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29/1 "/>
</bind>
</comp>

<comp id="173" class="1004" name="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30_fu_173">
<pin_list>
<pin id="174" dir="0" index="0" bw="8" slack="0"/>
<pin id="175" dir="1" index="1" bw="32" slack="2147483647"/>
</pin_list>
<bind>
<opcode="muxlogic(592) " fcode="muxlogic"/>
<opset="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30/1 "/>
</bind>
</comp>

<comp id="177" class="1004" name="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31_fu_177">
<pin_list>
<pin id="178" dir="0" index="0" bw="8" slack="0"/>
<pin id="179" dir="1" index="1" bw="32" slack="2147483647"/>
</pin_list>
<bind>
<opcode="muxlogic(592) " fcode="muxlogic"/>
<opset="muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31/1 "/>
</bind>
</comp>

<comp id="181" class="1004" name="store_ln11_store_fu_181">
<pin_list>
<pin id="182" dir="0" index="0" bw="10" slack="0"/>
<pin id="183" dir="0" index="1" bw="10" slack="0"/>
<pin id="184" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln11/1 "/>
</bind>
</comp>

<comp id="186" class="1004" name="tmp_i_fu_186">
<pin_list>
<pin id="187" dir="0" index="0" bw="32" slack="0"/>
<pin id="188" dir="0" index="1" bw="2" slack="0"/>
<pin id="189" dir="0" index="2" bw="32" slack="0"/>
<pin id="190" dir="0" index="3" bw="2" slack="0"/>
<pin id="191" dir="0" index="4" bw="32" slack="0"/>
<pin id="192" dir="0" index="5" bw="2" slack="0"/>
<pin id="193" dir="0" index="6" bw="32" slack="0"/>
<pin id="194" dir="0" index="7" bw="2" slack="0"/>
<pin id="195" dir="0" index="8" bw="32" slack="0"/>
<pin id="196" dir="0" index="9" bw="32" slack="0"/>
<pin id="197" dir="0" index="10" bw="2" slack="1"/>
<pin id="198" dir="1" index="11" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="sparsemux(1197) " fcode="sparsemux"/>
<opset="tmp_i/2 "/>
</bind>
</comp>

<comp id="209" class="1004" name="bitcast_ln14_fu_209">
<pin_list>
<pin id="210" dir="0" index="0" bw="32" slack="0"/>
<pin id="211" dir="1" index="1" bw="32" slack="0"/>
</pin_list>
<bind>
<opcode="bitcast(44) " fcode="bitcast"/>
<opset="bitcast_ln14/2 "/>
</bind>
</comp>

<comp id="214" class="1004" name="muxLogicFIFOData_to_write_ln14_fu_214">
<pin_list>
<pin id="215" dir="0" index="0" bw="32" slack="0"/>
<pin id="216" dir="1" index="1" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="muxlogic(592) " fcode="muxlogic"/>
<opset="muxLogicFIFOData_to_write_ln14/2 "/>
</bind>
</comp>

<comp id="218" class="1005" name="i_reg_218">
<pin_list>
<pin id="219" dir="0" index="0" bw="10" slack="0"/>
<pin id="220" dir="1" index="1" bw="10" slack="0"/>
</pin_list>
<bind>
<opset="i "/>
</bind>
</comp>

<comp id="228" class="1005" name="trunc_ln11_reg_228">
<pin_list>
<pin id="229" dir="0" index="0" bw="2" slack="1"/>
<pin id="230" dir="1" index="1" bw="2" slack="1"/>
</pin_list>
<bind>
<opset="trunc_ln11 "/>
</bind>
</comp>

<comp id="233" class="1005" name="llama_inference_hls_top_float_float_float_float_float_float_float_24_reg_233">
<pin_list>
<pin id="234" dir="0" index="0" bw="8" slack="1"/>
<pin id="235" dir="1" index="1" bw="8" slack="1"/>
</pin_list>
<bind>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_24 "/>
</bind>
</comp>

<comp id="238" class="1005" name="llama_inference_hls_top_float_float_float_float_float_float_float_25_reg_238">
<pin_list>
<pin id="239" dir="0" index="0" bw="8" slack="1"/>
<pin id="240" dir="1" index="1" bw="8" slack="1"/>
</pin_list>
<bind>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_25 "/>
</bind>
</comp>

<comp id="243" class="1005" name="llama_inference_hls_top_float_float_float_float_float_float_float_26_reg_243">
<pin_list>
<pin id="244" dir="0" index="0" bw="8" slack="1"/>
<pin id="245" dir="1" index="1" bw="8" slack="1"/>
</pin_list>
<bind>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_26 "/>
</bind>
</comp>

<comp id="248" class="1005" name="llama_inference_hls_top_float_float_float_float_float_float_float_27_reg_248">
<pin_list>
<pin id="249" dir="0" index="0" bw="8" slack="1"/>
<pin id="250" dir="1" index="1" bw="8" slack="1"/>
</pin_list>
<bind>
<opset="llama_inference_hls_top_float_float_float_float_float_float_float_27 "/>
</bind>
</comp>

</comp_list>

<net_list>
<net id="63"><net_src comp="10" pin="0"/><net_sink comp="60" pin=0"/></net>

<net id="69"><net_src comp="58" pin="0"/><net_sink comp="64" pin=0"/></net>

<net id="70"><net_src comp="8" pin="0"/><net_sink comp="64" pin=1"/></net>

<net id="76"><net_src comp="0" pin="0"/><net_sink comp="71" pin=0"/></net>

<net id="77"><net_src comp="34" pin="0"/><net_sink comp="71" pin=1"/></net>

<net id="83"><net_src comp="2" pin="0"/><net_sink comp="78" pin=0"/></net>

<net id="84"><net_src comp="34" pin="0"/><net_sink comp="78" pin=1"/></net>

<net id="90"><net_src comp="4" pin="0"/><net_sink comp="85" pin=0"/></net>

<net id="91"><net_src comp="34" pin="0"/><net_sink comp="85" pin=1"/></net>

<net id="97"><net_src comp="6" pin="0"/><net_sink comp="92" pin=0"/></net>

<net id="98"><net_src comp="34" pin="0"/><net_sink comp="92" pin=1"/></net>

<net id="104"><net_src comp="71" pin="3"/><net_sink comp="99" pin=0"/></net>

<net id="110"><net_src comp="78" pin="3"/><net_sink comp="105" pin=0"/></net>

<net id="116"><net_src comp="85" pin="3"/><net_sink comp="111" pin=0"/></net>

<net id="122"><net_src comp="92" pin="3"/><net_sink comp="117" pin=0"/></net>

<net id="127"><net_src comp="22" pin="0"/><net_sink comp="123" pin=0"/></net>

<net id="135"><net_src comp="128" pin="1"/><net_sink comp="131" pin=0"/></net>

<net id="136"><net_src comp="24" pin="0"/><net_sink comp="131" pin=1"/></net>

<net id="141"><net_src comp="128" pin="1"/><net_sink comp="137" pin=0"/></net>

<net id="142"><net_src comp="26" pin="0"/><net_sink comp="137" pin=1"/></net>

<net id="146"><net_src comp="128" pin="1"/><net_sink comp="143" pin=0"/></net>

<net id="153"><net_src comp="28" pin="0"/><net_sink comp="147" pin=0"/></net>

<net id="154"><net_src comp="128" pin="1"/><net_sink comp="147" pin=1"/></net>

<net id="155"><net_src comp="30" pin="0"/><net_sink comp="147" pin=2"/></net>

<net id="156"><net_src comp="32" pin="0"/><net_sink comp="147" pin=3"/></net>

<net id="160"><net_src comp="147" pin="4"/><net_sink comp="157" pin=0"/></net>

<net id="161"><net_src comp="157" pin="1"/><net_sink comp="71" pin=2"/></net>

<net id="162"><net_src comp="157" pin="1"/><net_sink comp="78" pin=2"/></net>

<net id="163"><net_src comp="157" pin="1"/><net_sink comp="85" pin=2"/></net>

<net id="164"><net_src comp="157" pin="1"/><net_sink comp="92" pin=2"/></net>

<net id="168"><net_src comp="71" pin="3"/><net_sink comp="165" pin=0"/></net>

<net id="172"><net_src comp="78" pin="3"/><net_sink comp="169" pin=0"/></net>

<net id="176"><net_src comp="85" pin="3"/><net_sink comp="173" pin=0"/></net>

<net id="180"><net_src comp="92" pin="3"/><net_sink comp="177" pin=0"/></net>

<net id="185"><net_src comp="131" pin="2"/><net_sink comp="181" pin=0"/></net>

<net id="199"><net_src comp="46" pin="0"/><net_sink comp="186" pin=0"/></net>

<net id="200"><net_src comp="48" pin="0"/><net_sink comp="186" pin=1"/></net>

<net id="201"><net_src comp="99" pin="3"/><net_sink comp="186" pin=2"/></net>

<net id="202"><net_src comp="50" pin="0"/><net_sink comp="186" pin=3"/></net>

<net id="203"><net_src comp="105" pin="3"/><net_sink comp="186" pin=4"/></net>

<net id="204"><net_src comp="52" pin="0"/><net_sink comp="186" pin=5"/></net>

<net id="205"><net_src comp="111" pin="3"/><net_sink comp="186" pin=6"/></net>

<net id="206"><net_src comp="54" pin="0"/><net_sink comp="186" pin=7"/></net>

<net id="207"><net_src comp="117" pin="3"/><net_sink comp="186" pin=8"/></net>

<net id="208"><net_src comp="56" pin="0"/><net_sink comp="186" pin=9"/></net>

<net id="212"><net_src comp="186" pin="11"/><net_sink comp="209" pin=0"/></net>

<net id="213"><net_src comp="209" pin="1"/><net_sink comp="64" pin=2"/></net>

<net id="217"><net_src comp="209" pin="1"/><net_sink comp="214" pin=0"/></net>

<net id="221"><net_src comp="60" pin="1"/><net_sink comp="218" pin=0"/></net>

<net id="222"><net_src comp="218" pin="1"/><net_sink comp="123" pin=1"/></net>

<net id="223"><net_src comp="218" pin="1"/><net_sink comp="128" pin=0"/></net>

<net id="224"><net_src comp="218" pin="1"/><net_sink comp="181" pin=1"/></net>

<net id="231"><net_src comp="143" pin="1"/><net_sink comp="228" pin=0"/></net>

<net id="232"><net_src comp="228" pin="1"/><net_sink comp="186" pin=10"/></net>

<net id="236"><net_src comp="71" pin="3"/><net_sink comp="233" pin=0"/></net>

<net id="237"><net_src comp="233" pin="1"/><net_sink comp="99" pin=0"/></net>

<net id="241"><net_src comp="78" pin="3"/><net_sink comp="238" pin=0"/></net>

<net id="242"><net_src comp="238" pin="1"/><net_sink comp="105" pin=0"/></net>

<net id="246"><net_src comp="85" pin="3"/><net_sink comp="243" pin=0"/></net>

<net id="247"><net_src comp="243" pin="1"/><net_sink comp="111" pin=0"/></net>

<net id="251"><net_src comp="92" pin="3"/><net_sink comp="248" pin=0"/></net>

<net id="252"><net_src comp="248" pin="1"/><net_sink comp="117" pin=0"/></net>

</net_list>

</model> 
---------------- Datapath Model END ------------------

* FSMD analyzer results:
  - Output states:
	Port: input1_stream | {2 }
 - Input state : 
	Port: load_vec : llama_inference_hls_top_float_float_float_float_float_float_float_7 | {1 2 }
	Port: load_vec : llama_inference_hls_top_float_float_float_float_float_float_float_6 | {1 2 }
	Port: load_vec : llama_inference_hls_top_float_float_float_float_float_float_float_5 | {1 2 }
	Port: load_vec : llama_inference_hls_top_float_float_float_float_float_float_float_4 | {1 2 }
  - Chain level:
	State 1
		store_ln11 : 1
		i_15 : 1
		add_ln11 : 2
		icmp_ln11 : 2
		br_ln11 : 3
		trunc_ln11 : 2
		lshr_ln : 2
		zext_ln11 : 3
		llama_inference_hls_top_float_float_float_float_float_float_float_24 : 4
		llama_inference_hls_top_float_float_float_float_float_float_float_25 : 4
		llama_inference_hls_top_float_float_float_float_float_float_float_26 : 4
		llama_inference_hls_top_float_float_float_float_float_float_float_27 : 4
		muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28 : 5
		llama_inference_hls_top_float_float_float_float_float_float_float_28 : 5
		muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29 : 5
		llama_inference_hls_top_float_float_float_float_float_float_float_29 : 5
		muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30 : 5
		llama_inference_hls_top_float_float_float_float_float_float_float_30 : 5
		muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31 : 5
		llama_inference_hls_top_float_float_float_float_float_float_float_31 : 5
		store_ln11 : 3
	State 2
		tmp_i : 1
		bitcast_ln14 : 2
		muxLogicFIFOData_to_write_ln14 : 3
		write_ln14 : 3


============================================================
+ Verbose Summary: Datapath Resource usage 
============================================================

* Functional unit list:
|----------|------------------------------------------------------------------------------------------------|---------|---------|
| Operation|                                         Functional Unit                                        |    FF   |   LUT   |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
| sparsemux|                                          tmp_i_fu_186                                          |    0    |    32   |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|    add   |                                         add_ln11_fu_131                                        |    0    |    10   |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|   icmp   |                                        icmp_ln11_fu_137                                        |    0    |    4    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|   write  |                                     write_ln14_write_fu_64                                     |    0    |    0    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|   trunc  |                                        trunc_ln11_fu_143                                       |    0    |    0    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|partselect|                                         lshr_ln_fu_147                                         |    0    |    0    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|   zext   |                                        zext_ln11_fu_157                                        |    0    |    0    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|          | muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_28_fu_165 |    0    |    0    |
|          | muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_29_fu_169 |    0    |    0    |
| muxlogic | muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_30_fu_173 |    0    |    0    |
|          | muxLogicRAMAddr_to_llama_inference_hls_top_float_float_float_float_float_float_float_31_fu_177 |    0    |    0    |
|          |                              muxLogicFIFOData_to_write_ln14_fu_214                             |    0    |    0    |
|----------|------------------------------------------------------------------------------------------------|---------|---------|
|   Total  |                                                                                                |    0    |    46   |
|----------|------------------------------------------------------------------------------------------------|---------|---------|

Memories:
N/A

* Register list:
+----------------------------------------------------------------------------+--------+
|                                                                            |   FF   |
+----------------------------------------------------------------------------+--------+
|                                  i_reg_218                                 |   10   |
|llama_inference_hls_top_float_float_float_float_float_float_float_24_reg_233|    8   |
|llama_inference_hls_top_float_float_float_float_float_float_float_25_reg_238|    8   |
|llama_inference_hls_top_float_float_float_float_float_float_float_26_reg_243|    8   |
|llama_inference_hls_top_float_float_float_float_float_float_float_27_reg_248|    8   |
|                             trunc_ln11_reg_228                             |    2   |
+----------------------------------------------------------------------------+--------+
|                                    Total                                   |   44   |
+----------------------------------------------------------------------------+--------+

* Multiplexer (MUX) list: 
|-------------------|------|------|------|--------||---------||---------||---------|
|        Comp       |  Pin | Size |  BW  | S x BW ||  Delay  ||    FF   ||   LUT   |
|-------------------|------|------|------|--------||---------||---------||---------|
|  grp_access_fu_99 |  p0  |   2  |   8  |   16   ||    0    ||    8    |
| grp_access_fu_105 |  p0  |   2  |   8  |   16   ||    0    ||    8    |
| grp_access_fu_111 |  p0  |   2  |   8  |   16   ||    0    ||    8    |
| grp_access_fu_117 |  p0  |   2  |   8  |   16   ||    0    ||    8    |
|-------------------|------|------|------|--------||---------||---------||---------|
|       Total       |      |      |      |   64   ||   1.44  ||    0    ||    32   |
|-------------------|------|------|------|--------||---------||---------||---------|



* Summary:
+-----------+--------+--------+--------+
|           |  Delay |   FF   |   LUT  |
+-----------+--------+--------+--------+
|  Function |    -   |    0   |   46   |
|   Memory  |    -   |    -   |    -   |
|Multiplexer|    1   |    0   |   32   |
|  Register |    -   |   44   |    -   |
+-----------+--------+--------+--------+
|   Total   |    1   |   44   |   78   |
+-----------+--------+--------+--------+
